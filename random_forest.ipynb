{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Random Forest Exercises\n",
    "\n",
    "* Work with titanic data to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#custom imports\n",
    "from prepare import prep_titanic, split_data\n",
    "from acquire import new_titanic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex  sibsp  parch     fare  embark_town  alone\n",
       "0         0       3    male      1      0   7.2500  Southampton      0\n",
       "1         1       1  female      1      0  71.2833    Cherbourg      0\n",
       "2         1       3  female      0      0   7.9250  Southampton      1\n",
       "3         1       1  female      1      0  53.1000  Southampton      0\n",
       "4         0       3    male      0      0   8.0500  Southampton      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire data\n",
    "titanic = prep_titanic(new_titanic_data())\n",
    "titanic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['sex'] = titanic.sex.map({'male': 1, 'female': 0})\n",
    "titanic['embark_town'] = titanic.embark_town.map({'Southampton': 0, 'Queenstown': 1, 'Cherbourg': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass  sex  sibsp  parch     fare  embark_town  alone\n",
       "0         0       3    1      1      0   7.2500            0      0\n",
       "1         1       1    0      1      0  71.2833            2      0\n",
       "2         1       3    0      0      0   7.9250            0      1\n",
       "3         1       1    0      1      0  53.1000            0      0\n",
       "4         0       3    1      0      0   8.0500            0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validate, split data\n",
    "train, validate, test = split_data(titanic, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      survived  pclass  sex  sibsp  parch     fare  embark_town  alone\n",
       "818         0       3    1      0      0   6.4500            0      1\n",
       "98          1       2    0      0      1  23.0000            0      0\n",
       "825         0       3    1      0      0   6.9500            1      1\n",
       "573         1       3    0      0      0   7.7500            1      1\n",
       "322         1       2    0      0      0  12.3500            1      1\n",
       "..        ...     ...  ...    ...    ...      ...          ...    ...\n",
       "446         1       2    0      0      1  19.5000            0      0\n",
       "491         0       3    1      0      0   7.2500            0      1\n",
       "503         0       3    0      0      0   9.5875            0      1\n",
       "748         0       1    1      1      0  53.1000            0      0\n",
       "406         0       3    1      0      0   7.7500            0      1\n",
       "\n",
       "[310 rows x 8 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolate the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know what our X and y are, let's be explicit about defining them\n",
    "X_train = train.drop(columns='survived')\n",
    "y_train = train.survived\n",
    "\n",
    "X_val = validate.drop(columns='survived')\n",
    "y_val = validate.survived\n",
    "\n",
    "X_test = test.drop(columns='survived')\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline prediction: 0\n",
      "Baseline accuracy: 0.6161290322580645\n"
     ]
    }
   ],
   "source": [
    "baseline = y_train.mode()\n",
    "baseline_accuracy = y_train == 0\n",
    "print(f\"Baseline prediction: {(baseline[0])}\")\n",
    "print(f\"Baseline accuracy: {(baseline_accuracy.mean())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "forest1 = RandomForestClassifier(min_samples_leaf= 1, max_depth=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "forest1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the predictions\n",
    "y_predictions = forest1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9387096774193548"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get accuracy score for first model\n",
    "forest1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[184,   7],\n",
       "       [ 12, 107]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_train, y_predictions)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x14936b040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp_conf = ConfusionMatrixDisplay(confusion_matrix=conf,display_labels=forest1.classes_)\n",
    "disp_conf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of depth 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.93871</td>\n",
       "      <td>0.938686</td>\n",
       "      <td>0.938707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.963351</td>\n",
       "      <td>0.899160</td>\n",
       "      <td>0.93871</td>\n",
       "      <td>0.931255</td>\n",
       "      <td>0.938710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.950904</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.93871</td>\n",
       "      <td>0.934680</td>\n",
       "      <td>0.938448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>191.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.93871</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.938776    0.938596   0.93871    0.938686      0.938707\n",
       "recall       0.963351    0.899160   0.93871    0.931255      0.938710\n",
       "f1-score     0.950904    0.918455   0.93871    0.934680      0.938448\n",
       "support    191.000000  119.000000   0.93871  310.000000    310.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "\n",
    "print(\"Tree of depth 10\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 7, 12, 107)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.ravel returns a contigious array\n",
    "TN, FP, FN, TP = confusion_matrix(y_train, y_predictions).ravel()\n",
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.87\n",
      "True Positive Rate: 89.92\n",
      "False Positive Rate: 3.66\n",
      "True Negative Rate: 96.34\n",
      "False Negative Rate: 10.08\n",
      "Precision: 93.86\n",
      "F1 score: 91.85\n",
      "Support (0): 119\n",
      "Support (1): 191\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "ALL = TP + FP + FN + TN\n",
    "acc = (TP + TN) / ALL\n",
    "print(f\"Accuracy: {round(acc*100, 2)}\")\n",
    "\n",
    "# true positive rate, also recall\n",
    "TPR = recall = TP/ (TP + FN)\n",
    "print(f\"True Positive Rate: {round(TPR*100, 2)}\")\n",
    "\n",
    "# false positive rate\n",
    "FPR = FP / (FP + TN)\n",
    "print(f\"False Positive Rate: {round(FPR*100, 2)}\")\n",
    "\n",
    "# true negative rate\n",
    "TNR = TN / (TN + FP)\n",
    "print(f\"True Negative Rate: {round(TNR*100, 2)}\")\n",
    "\n",
    "# false negative rate\n",
    "FNR = FN / (FN + TP)\n",
    "print(f\"False Negative Rate: {round(FNR*100, 2)}\")\n",
    "\n",
    "# precision\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision: {round(precision*100, 2)}\")\n",
    "\n",
    "# f1\n",
    "f1_score = 2 * (precision*recall) / (precision+recall)\n",
    "print(f\"F1 score: {round(f1_score*100, 2)}\")\n",
    "\n",
    "# support\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_per_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.103515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.858065</td>\n",
       "      <td>0.768657</td>\n",
       "      <td>0.089408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.848387</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.072268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.048676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.835484</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.051902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.816129</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.025084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.031536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.024073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.816129</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.017622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.036784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.036784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.809677</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.011170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0.816129</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.025084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.816129</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.017622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.796774</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.050506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.796774</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.065431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.068657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777419</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.031151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_samples_per_leaf  max_depth  train_accuracy  validate_accuracy  \\\n",
       "0                      2         18        0.887097           0.783582   \n",
       "1                      3         17        0.858065           0.768657   \n",
       "2                      4         16        0.848387           0.776119   \n",
       "3                      5         15        0.832258           0.783582   \n",
       "4                      6         14        0.835484           0.783582   \n",
       "5                      7         13        0.816129           0.791045   \n",
       "6                      8         12        0.822581           0.791045   \n",
       "7                      9         11        0.822581           0.798507   \n",
       "8                     10         10        0.816129           0.798507   \n",
       "9                     11          9        0.812903           0.776119   \n",
       "10                    12          8        0.812903           0.776119   \n",
       "11                    13          7        0.809677           0.798507   \n",
       "12                    14          6        0.816129           0.791045   \n",
       "13                    15          5        0.816129           0.798507   \n",
       "14                    16          4        0.796774           0.746269   \n",
       "15                    17          3        0.796774           0.731343   \n",
       "16                    18          2        0.800000           0.731343   \n",
       "17                    19          1        0.777419           0.746269   \n",
       "\n",
       "    difference  \n",
       "0     0.103515  \n",
       "1     0.089408  \n",
       "2     0.072268  \n",
       "3     0.048676  \n",
       "4     0.051902  \n",
       "5     0.025084  \n",
       "6     0.031536  \n",
       "7     0.024073  \n",
       "8     0.017622  \n",
       "9     0.036784  \n",
       "10    0.036784  \n",
       "11    0.011170  \n",
       "12    0.025084  \n",
       "13    0.017622  \n",
       "14    0.050506  \n",
       "15    0.065431  \n",
       "16    0.068657  \n",
       "17    0.031151  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for-loop through so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "max_depth = 20\n",
    "\n",
    "for i in range(2, max_depth):\n",
    "    # Make the model\n",
    "    depth = max_depth - i\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=42)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_val, y_val)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only using max_depth evaluaiton metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.809677</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.078334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.075108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.056139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.858065</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.074482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.091815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.906452</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.115407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.929032</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.130525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.140202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.140202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.155128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           2        0.809677           0.731343    0.078334\n",
       "1           3        0.806452           0.731343    0.075108\n",
       "2           4        0.832258           0.776119    0.056139\n",
       "3           5        0.858065           0.783582    0.074482\n",
       "4           6        0.890323           0.798507    0.091815\n",
       "5           7        0.906452           0.791045    0.115407\n",
       "6           8        0.929032           0.798507    0.130525\n",
       "7           9        0.938710           0.798507    0.140202\n",
       "8          10        0.938710           0.798507    0.140202\n",
       "9          11        0.938710           0.783582    0.155128\n",
       "10         12        0.938710           0.783582    0.155128\n",
       "11         13        0.938710           0.783582    0.155128\n",
       "12         14        0.938710           0.783582    0.155128\n",
       "13         15        0.938710           0.783582    0.155128\n",
       "14         16        0.938710           0.783582    0.155128\n",
       "15         17        0.938710           0.783582    0.155128\n",
       "16         18        0.938710           0.783582    0.155128\n",
       "17         19        0.938710           0.783582    0.155128\n",
       "18         20        0.938710           0.783582    0.155128\n",
       "19         21        0.938710           0.783582    0.155128\n",
       "20         22        0.938710           0.783582    0.155128\n",
       "21         23        0.938710           0.783582    0.155128\n",
       "22         24        0.938710           0.783582    0.155128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=42)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first then check validate\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_val, y_val)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?\n",
    "\n",
    "* min_samples_leaf ~ 8 and max-depth ~ 8 performs the best for close metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decreasing min_samples_leaf and increasing max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_per_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.077130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.070679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.073905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.073905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>0.783871</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.067453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.070679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.783871</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.067453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0.783871</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.067453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.783871</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.067453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>0.780645</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.064227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.057776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.057776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>0.770968</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.054550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.057776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>0.777419</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.061001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>0.780645</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.064227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>0.783871</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.067453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>0.783871</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.067453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_samples_per_leaf  max_depth  train_accuracy  validate_accuracy  \\\n",
       "0                     22          2        0.793548           0.716418   \n",
       "1                     23          3        0.787097           0.716418   \n",
       "2                     24          4        0.790323           0.716418   \n",
       "3                     25          5        0.790323           0.716418   \n",
       "4                     26          6        0.783871           0.716418   \n",
       "5                     27          7        0.787097           0.716418   \n",
       "6                     28          8        0.783871           0.716418   \n",
       "7                     29          9        0.783871           0.716418   \n",
       "8                     30         10        0.783871           0.716418   \n",
       "9                     31         11        0.780645           0.716418   \n",
       "10                    32         12        0.774194           0.716418   \n",
       "11                    33         13        0.774194           0.716418   \n",
       "12                    34         14        0.770968           0.716418   \n",
       "13                    35         15        0.774194           0.716418   \n",
       "14                    36         16        0.777419           0.716418   \n",
       "15                    37         17        0.780645           0.716418   \n",
       "16                    38         18        0.783871           0.716418   \n",
       "17                    39         19        0.783871           0.716418   \n",
       "\n",
       "    difference  \n",
       "0     0.077130  \n",
       "1     0.070679  \n",
       "2     0.073905  \n",
       "3     0.073905  \n",
       "4     0.067453  \n",
       "5     0.070679  \n",
       "6     0.067453  \n",
       "7     0.067453  \n",
       "8     0.067453  \n",
       "9     0.064227  \n",
       "10    0.057776  \n",
       "11    0.057776  \n",
       "12    0.054550  \n",
       "13    0.057776  \n",
       "14    0.061001  \n",
       "15    0.064227  \n",
       "16    0.067453  \n",
       "17    0.067453  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "max_depth = 20\n",
    "\n",
    "for i in range(2, max_depth):\n",
    "    # Make the model\n",
    "    depth = i\n",
    "    n_samples = max_depth + i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_val, y_val)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increase both min_samples_leaf and max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_per_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.086808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.816129</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>0.062398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.829032</td>\n",
       "      <td>0.768657</td>\n",
       "      <td>0.060376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.829032</td>\n",
       "      <td>0.768657</td>\n",
       "      <td>0.060376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.055128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.056139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.829032</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.052913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.829032</td>\n",
       "      <td>0.768657</td>\n",
       "      <td>0.060376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.079345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.079345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.069668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.063216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.796774</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.072894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.066442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.062205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.083582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.062205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.076119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_samples_per_leaf  max_depth  train_accuracy  validate_accuracy  \\\n",
       "0                      2          2        0.803226           0.716418   \n",
       "1                      3          3        0.816129           0.753731   \n",
       "2                      4          4        0.829032           0.768657   \n",
       "3                      5          5        0.829032           0.768657   \n",
       "4                      6          6        0.838710           0.783582   \n",
       "5                      7          7        0.832258           0.776119   \n",
       "6                      8          8        0.829032           0.776119   \n",
       "7                      9          9        0.829032           0.768657   \n",
       "8                     10         10        0.803226           0.723881   \n",
       "9                     11         11        0.803226           0.723881   \n",
       "10                    12         12        0.793548           0.723881   \n",
       "11                    13         13        0.787097           0.723881   \n",
       "12                    14         14        0.796774           0.723881   \n",
       "13                    15         15        0.790323           0.723881   \n",
       "14                    16         16        0.793548           0.731343   \n",
       "15                    17         17        0.800000           0.716418   \n",
       "16                    18         18        0.793548           0.731343   \n",
       "17                    19         19        0.800000           0.723881   \n",
       "\n",
       "    difference  \n",
       "0     0.086808  \n",
       "1     0.062398  \n",
       "2     0.060376  \n",
       "3     0.060376  \n",
       "4     0.055128  \n",
       "5     0.056139  \n",
       "6     0.052913  \n",
       "7     0.060376  \n",
       "8     0.079345  \n",
       "9     0.079345  \n",
       "10    0.069668  \n",
       "11    0.063216  \n",
       "12    0.072894  \n",
       "13    0.066442  \n",
       "14    0.062205  \n",
       "15    0.083582  \n",
       "16    0.062205  \n",
       "17    0.076119  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "max_depth = 20\n",
    "\n",
    "for i in range(2, max_depth):\n",
    "    # Make the model\n",
    "    depth = i\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_val, y_val)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed max_depth and increasing min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_per_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.861290</td>\n",
       "      <td>0.768657</td>\n",
       "      <td>0.092634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.861290</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.100096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.841935</td>\n",
       "      <td>0.768657</td>\n",
       "      <td>0.073279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.055128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.055128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.056139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.079538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.816129</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.069860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.076119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.079345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.796774</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.072894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.069668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0.796774</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.072894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.066442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.062205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.083582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.062205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.076119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.077130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.070679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.077130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.070679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.073905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_samples_per_leaf  max_depth  train_accuracy  validate_accuracy  \\\n",
       "0                      2          6        0.861290           0.768657   \n",
       "1                      3          6        0.861290           0.761194   \n",
       "2                      4          6        0.841935           0.768657   \n",
       "3                      5          6        0.838710           0.783582   \n",
       "4                      6          6        0.838710           0.783582   \n",
       "5                      7          6        0.832258           0.776119   \n",
       "6                      8          6        0.825806           0.746269   \n",
       "7                      9          6        0.816129           0.746269   \n",
       "8                     10          6        0.800000           0.723881   \n",
       "9                     11          6        0.803226           0.723881   \n",
       "10                    12          6        0.796774           0.723881   \n",
       "11                    13          6        0.793548           0.723881   \n",
       "12                    14          6        0.796774           0.723881   \n",
       "13                    15          6        0.790323           0.723881   \n",
       "14                    16          6        0.793548           0.731343   \n",
       "15                    17          6        0.800000           0.716418   \n",
       "16                    18          6        0.793548           0.731343   \n",
       "17                    19          6        0.800000           0.723881   \n",
       "18                    20          6        0.793548           0.716418   \n",
       "19                    21          6        0.787097           0.716418   \n",
       "20                    22          6        0.793548           0.716418   \n",
       "21                    23          6        0.787097           0.716418   \n",
       "22                    24          6        0.790323           0.716418   \n",
       "\n",
       "    difference  \n",
       "0     0.092634  \n",
       "1     0.100096  \n",
       "2     0.073279  \n",
       "3     0.055128  \n",
       "4     0.055128  \n",
       "5     0.056139  \n",
       "6     0.079538  \n",
       "7     0.069860  \n",
       "8     0.076119  \n",
       "9     0.079345  \n",
       "10    0.072894  \n",
       "11    0.069668  \n",
       "12    0.072894  \n",
       "13    0.066442  \n",
       "14    0.062205  \n",
       "15    0.083582  \n",
       "16    0.062205  \n",
       "17    0.076119  \n",
       "18    0.077130  \n",
       "19    0.070679  \n",
       "20    0.077130  \n",
       "21    0.070679  \n",
       "22    0.073905  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    depth = 6\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_val, y_val)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
